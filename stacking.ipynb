{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stacking",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tetrar124/Safety_Science/blob/master/stacking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkYUIzoMjcqW",
        "colab_type": "code",
        "outputId": "416b2116-ec97-48a0-8f79-7ded403db867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install fastFM\n",
        "!pip install -U mlxtend\n",
        "!pip install -U pandas\n",
        "!pip install rgf_python\n",
        "#!pip install -U tensorflow-gpu\n",
        "!pip install rgf-python\n",
        "!pip install bayesian-optimization"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastFM\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/15/fdbb9b9455efa48ffb07b9880a1e567e0c7a7de0acc4aa7f1c5ba9ce4f2c/fastFM-0.2.11-cp36-cp36m-manylinux1_x86_64.whl (483kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 45.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastFM) (1.16.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastFM) (1.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastFM) (0.21.3)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fastFM) (0.29.13)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fastFM) (0.13.2)\n",
            "Installing collected packages: fastFM\n",
            "Successfully installed fastFM-0.2.11\n",
            "Collecting mlxtend\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/04/c362f34f666f0ddc7cf593805e64d64fa670ed96fd9302e68549dd48287d/mlxtend-0.17.0-py2.py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.16.2 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from mlxtend) (41.0.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.13.2 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (0.13.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20.3 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (0.21.3)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (0.24.2)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (3.0.3)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->mlxtend) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->mlxtend) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.4.2)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas>=0.24.2->mlxtend) (1.12.0)\n",
            "Installing collected packages: mlxtend\n",
            "  Found existing installation: mlxtend 0.14.0\n",
            "    Uninstalling mlxtend-0.14.0:\n",
            "      Successfully uninstalled mlxtend-0.14.0\n",
            "Successfully installed mlxtend-0.17.0\n",
            "Collecting pandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/9a/7eb9952f4b4d73fbd75ad1d5d6112f407e695957444cb695cbb3cdab918a/pandas-0.25.0-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5MB 34.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Collecting python-dateutil>=2.6.1 (from pandas)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 20.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.16.4)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=0.24.0, but you'll have pandas 0.25.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: python-dateutil, pandas\n",
            "  Found existing installation: python-dateutil 2.5.3\n",
            "    Uninstalling python-dateutil-2.5.3:\n",
            "      Successfully uninstalled python-dateutil-2.5.3\n",
            "  Found existing installation: pandas 0.24.2\n",
            "    Uninstalling pandas-0.24.2:\n",
            "      Successfully uninstalled pandas-0.24.2\n",
            "Successfully installed pandas-0.25.0 python-dateutil-2.8.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting rgf_python\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/7c/41f50b22c5a40614ffe8b3bfb857dbe7b09b843692697443d7811773f0a4/rgf_python-3.6.0-py2.py3-none-manylinux1_x86_64.whl (757kB)\n",
            "\r\u001b[K     |▍                               | 10kB 15.5MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 20.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 25.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 29.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 32.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 36.1MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 36.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81kB 37.3MB/s eta 0:00:01\r\u001b[K     |████                            | 92kB 38.9MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 40.4MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 40.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 40.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 133kB 40.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 40.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 153kB 40.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 163kB 40.4MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 174kB 40.4MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 184kB 40.4MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 194kB 40.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 204kB 40.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 40.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 225kB 40.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235kB 40.4MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 245kB 40.4MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 256kB 40.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 266kB 40.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 276kB 40.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 40.4MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 296kB 40.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 307kB 40.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 317kB 40.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 327kB 40.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 337kB 40.4MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 348kB 40.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 358kB 40.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 368kB 40.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 378kB 40.4MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 389kB 40.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 399kB 40.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 409kB 40.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 419kB 40.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 430kB 40.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 440kB 40.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 450kB 40.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 460kB 40.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 471kB 40.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 481kB 40.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 491kB 40.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 501kB 40.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 512kB 40.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 522kB 40.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 532kB 40.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 542kB 40.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 552kB 40.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 563kB 40.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 573kB 40.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 583kB 40.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 593kB 40.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 604kB 40.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 614kB 40.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 624kB 40.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 634kB 40.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 645kB 40.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 655kB 40.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 665kB 40.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 675kB 40.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 686kB 40.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 696kB 40.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 706kB 40.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 716kB 40.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 727kB 40.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 737kB 40.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 747kB 40.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 757kB 40.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 40.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from rgf_python) (0.21.3)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->rgf_python) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->rgf_python) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->rgf_python) (0.13.2)\n",
            "Installing collected packages: rgf-python\n",
            "Successfully installed rgf-python-3.6.0\n",
            "Requirement already satisfied: rgf-python in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from rgf-python) (0.21.3)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->rgf-python) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->rgf-python) (1.3.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->rgf-python) (0.13.2)\n",
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/72/0c/173ac467d0a53e33e41b521e4ceba74a8ac7c7873d7b857a8fbdca88302d/bayesian-optimization-1.0.1.tar.gz\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.3.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.21.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.13.2)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.0.1-cp36-none-any.whl size=10031 sha256=939a7dd6a9d20293676c8bcc4000c3342ce3dc3a73c5047a82151490d41e2e3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/0d/3b/6b9d4477a34b3905f246ff4e7acf6aafd4cc9b77d473629b77\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBy40_OMlNFA",
        "colab_type": "code",
        "outputId": "f1bc7164-6460-4ac4-949f-476e609223a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My\\ Drive/colab/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq_yKxUzlg7B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "a0f9b5cd-8760-4a98-df96-e831eacbc7eb"
      },
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "import pandas as pd\n",
        "\n",
        "from lightgbm import LGBMRegressor\n",
        "from fastFM import sgd,als\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.model_selection import GridSearchCV,  cross_validate, StratifiedKFold\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "from mlxtend.regressor import StackingRegressor\n",
        "from mlxtend.feature_selection import ColumnSelector\n",
        "from rgf.sklearn import RGFRegressor\n",
        "import xgboost\n",
        "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.datasets import load_boston\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from PIL import Image\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.python.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.python.keras.preprocessing.image import load_img\n",
        "from tensorflow.python.keras.layers import Conv1D, MaxPooling1D,BatchNormalization\n",
        "from tensorflow.python.keras.layers import Activation, Dropout, Flatten, Input, Dense, LSTM,CuDNNLSTM\n",
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras.callbacks import TensorBoard\n",
        "from tensorflow.python.keras import applications\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin,RegressorMixin\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "import scipy as sp\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.decomposition import PCA\n",
        "os.chdir(r'/content/drive/My Drive/Data/Meram Chronic Data')\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from bayes_opt import BayesianOptimization"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAwtB5XPmTdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ejectCAS = ['10124-36-4', '108-88-3', '111991-09-4', '116-29-0', '120-12-7', '126833-17-8', '13171-21-6',\n",
        "                    '1333-82-0', '137-30-4', '148-79-8', '1582-09-8', '1610-18-0', '2058-46-0', '2104-64-5',\n",
        "                    '21725-46-2',\n",
        "                    '2303-17-5', '25311-71-1', '25812-30-0', '298-00-0', '298-04-4', '314-40-9', '330-54-1',\n",
        "                    '4170-30-3',\n",
        "                    '4717-38-8', '50-00-0', '52645-53-1', '55406-53-6', '56-35-9', '56-38-2', '60207-90-1', '6051-87-2',\n",
        "                    '62-53-3', '6317-18-6', '69-72-7', '7440-02-0', '7447-40-7', '7722-84-1', '7733-02-0', '7758-94-3',\n",
        "                    '80844-07-1', '82657-04-3', '84852-15-3', '86-73-7', '9016-45-9', '99-35-4']\n",
        "\n",
        "df =pd.read_csv('fishMorganMACCS.csv')\n",
        "#df2=pd.read_csv('chronicMACCSKeys_tanimoto.csv')\n",
        "#df2 = df2.drop(ejectCAS,axis=1).set_index('CAS').dropna(how='all', axis=1)\n",
        "baseDf = df\n",
        "extractDf =  df['CAS'].isin(ejectCAS)\n",
        "df = df[~df['CAS'].isin(ejectCAS)]\n",
        "#df = df.set_index('CAS')\n",
        "#df = pd.concat([df,df2],axis=1, join_axes=[df.index]).reset_index()\n",
        "y = df['logTox']\n",
        "#dropList = ['CAS','toxValue','logTox','HDonor', 'HAcceptors', 'AromaticHeterocycles', 'AromaticCarbocycles', 'FractionCSP3']\n",
        "dropList = ['CAS','toxValue','logTox']\n",
        "X = df.drop(columns=dropList)\n",
        "#Normalize\n",
        "def normalize(X):\n",
        "    changeList = []\n",
        "    for i,name in enumerate(X.columns):\n",
        "        if i <679:\n",
        "            changeList.append((0,1))\n",
        "        elif i > 692:\n",
        "            changeList.append((0,1))\n",
        "        else:\n",
        "            #try:\n",
        "            #name = float(name)\n",
        "            #except:\n",
        "            std =X[name].std()\n",
        "            mean = X[name].mean()\n",
        "            if std==0:\n",
        "              X[name] = X[name]\n",
        "            else:\n",
        "              X[name] = X[name].apply(lambda x: ((x - mean) * 1 / std + 0))\n",
        "            changeList.append((mean, std))\n",
        "    return X, changeList\n",
        "X2,_ = normalize(X)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuSEJd4pLFnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        def calcRMSE(real, pred):\n",
        "            RMSE = (np.sum((pred - real.tolist()) ** 2) / len(pred)) ** (1 / 2)\n",
        "            return RMSE\n",
        "\n",
        "        def calcCorr(real, pred):\n",
        "            corr = np.corrcoef(real, pred.flatten())[0, 1]\n",
        "            return corr\n",
        "        from sklearn.metrics import make_scorer\n",
        "        myScoreFunc = {'Accuracy': make_scorer(mean_squared_error),'RMSE': make_scorer(calcRMSE),\n",
        "                       'Correlation coefficient': make_scorer(calcCorr)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwbJzvczhPrj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "567ea8f2-c34d-4e9e-ef9c-c470cea6b12a"
      },
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1254, 5610)\n",
            "(1254,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRZicRTaotXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Lambda(lambda x: x+1,x**10)([1,2,3,4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RN5BGaXwSy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def dnnCalcACC(testmodel,X=X,name=None):\n",
        "        def calcRMSE(real, pred):\n",
        "            RMSE = (np.sum((pred - real.tolist()) ** 2) / len(pred)) ** (1 / 2)\n",
        "            return RMSE\n",
        "        def calcCorr(real, pred):\n",
        "            corr = np.corrcoef(real, pred.flatten())[0, 1]\n",
        "            return corr\n",
        "        from sklearn.metrics import make_scorer\n",
        "        myScoreFunc = {'RMSE': make_scorer(calcRMSE),\n",
        "                       'Correlation coefficient': make_scorer(calcCorr)}\n",
        "        cv = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "        Scores = cross_validate(testmodel, X, y, cv=cv, scoring=myScoreFunc,return_train_score=True)\n",
        "        RMSETmp = Scores['test_RMSE'].mean()\n",
        "        CORRTmP = Scores['test_Correlation coefficient'].mean()\n",
        "        trainRMSETmp = Scores['train_RMSE'].mean()\n",
        "        trainCORRTmP = Scores['train_Correlation coefficient'].mean()\n",
        "        print(name,'test', RMSETmp, CORRTmP)\n",
        "        print(name,'train',trainRMSETmp, trainCORRTmP)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESdy3BYhBpMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  class addDim(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        Y = np.expand_dims(X, axis=2)\n",
        "        return Y\n",
        "  #inputs = Input(((X2.shape[1],1)))\n",
        "  def LSTMmodel(X2=X2):\n",
        "    inputs = Input((X2.shape[1],1))\n",
        "    x = CuDNNLSTM(32,return_sequences=True)(inputs)\n",
        "    x = CuDNNLSTM(64,return_sequences=True)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x  = Dense(128, activation=\"relu\")(x)\n",
        "    predictions = Dense(1)(x)\n",
        "    model = Model(inputs=inputs, outputs=predictions)\n",
        "    model.compile(optimizer=\"adam\",loss='mean_squared_error')\n",
        "    return model\n",
        "  #nn = make_pipeline(addDim(),model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJSKn4l5EkkD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59e5126e-aa8f-40c1-d67d-f9733e2a9d78"
      },
      "source": [
        "inputs"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'input_19:0' shape=(?, 5610, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7ffvYXigk6p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "b235b86a-bce1-4771-937d-e7ed2cfe101e"
      },
      "source": [
        "        cv = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "        X2 = np.array(X)\n",
        "        y2 = np.array(y)\n",
        "        print(X2.shape)\n",
        "        folds = list(cv.split(X2))\n",
        "        resultscores=[]\n",
        "        for i,(train, test) in enumerate(cv.split(X2)):\n",
        "          model = LSTMmodel()\n",
        "          model.fit(np.expand_dims(X2[train], axis=2),y2[train])\n",
        "          score = model.evaluate(np.expand_dims(X2[test],axis=2), y2[test])\n",
        "          print(\"%s: %.2f%%\" % (model.metrics_names[0], scores))\n",
        "          resultscores.append(score)\n",
        "          tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1254, 5610)\n",
            "1128/1128 [==============================] - 14s 13ms/sample - loss: 2.7138\n",
            "126/126 [==============================] - 1s 6ms/sample - loss: 2.7178\n",
            "loss: 2.55%\n",
            "1128/1128 [==============================] - 15s 13ms/sample - loss: 3.5334\n",
            "126/126 [==============================] - 1s 6ms/sample - loss: 2.6643\n",
            "loss: 2.55%\n",
            "1128/1128 [==============================] - 14s 13ms/sample - loss: 2.9061\n",
            "126/126 [==============================] - 1s 6ms/sample - loss: 2.5896\n",
            "loss: 2.55%\n",
            "1128/1128 [==============================] - 14s 13ms/sample - loss: 2.6999\n",
            "126/126 [==============================] - 1s 6ms/sample - loss: 2.6583\n",
            "loss: 2.55%\n",
            "1129/1129 [==============================] - 14s 13ms/sample - loss: 3.0079\n",
            "125/125 [==============================] - 1s 6ms/sample - loss: 2.6807\n",
            "loss: 2.55%\n",
            "1129/1129 [==============================] - 15s 13ms/sample - loss: 3.2221\n",
            "125/125 [==============================] - 1s 6ms/sample - loss: 2.6305\n",
            "loss: 2.55%\n",
            "1129/1129 [==============================] - 14s 13ms/sample - loss: 3.5894\n",
            "125/125 [==============================] - 1s 6ms/sample - loss: 2.7916\n",
            "loss: 2.55%\n",
            "1129/1129 [==============================] - 15s 13ms/sample - loss: 3.8776\n",
            "125/125 [==============================] - 1s 6ms/sample - loss: 2.6033\n",
            "loss: 2.55%\n",
            "1129/1129 [==============================] - 14s 13ms/sample - loss: 3.5701\n",
            "125/125 [==============================] - 1s 6ms/sample - loss: 6.0282\n",
            "loss: 2.55%\n",
            " 640/1129 [================>.............] - ETA: 6s - loss: 3.9523"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcOA3KfR15tN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "d6863328-503f-462b-c235-436b7b5dd081"
      },
      "source": [
        "resultscores"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.468452075171092,\n",
              " 1.435398610811385,\n",
              " 1.1801072964592585,\n",
              " 1.186723684507703,\n",
              " 1.3473514127731323,\n",
              " 1.3805641765594483,\n",
              " 1.3650593090057372,\n",
              " 1.2791805620193482,\n",
              " 1.2453728828430175,\n",
              " 1.0534589042663574]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnFBBHNmXKh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    def calcACC(testmodel,X=X,name=None):\n",
        "        def calcRMSE(real, pred):\n",
        "            RMSE = (np.sum((pred - real.tolist()) ** 2) / len(pred)) ** (1 / 2)\n",
        "            return RMSE\n",
        "\n",
        "        def calcCorr(real, pred):\n",
        "            corr = np.corrcoef(real, pred.flatten())[0, 1]\n",
        "            return corr\n",
        "        from sklearn.metrics import make_scorer\n",
        "        myScoreFunc = {'RMSE': make_scorer(calcRMSE),\n",
        "                       'Correlation coefficient': make_scorer(calcCorr)}\n",
        "        cv = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "        Scores = cross_validate(testmodel, X, y, cv=cv, scoring=myScoreFunc,return_train_score=True)\n",
        "        RMSETmp = Scores['test_RMSE'].mean()\n",
        "        CORRTmP = Scores['test_Correlation coefficient'].mean()\n",
        "        trainRMSETmp = Scores['train_RMSE'].mean()\n",
        "        trainCORRTmP = Scores['train_Correlation coefficient'].mean()\n",
        "        print(name,'test', RMSETmp, CORRTmP)\n",
        "        print(name,'train',trainRMSETmp, trainCORRTmP)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wgr1T6YMDn-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb7r_ENjAkc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a= sp.sparse.csc_matrix(X2.values)\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "class sparseNorm(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        Y = normalize(sp.sparse.csc_matrix(X.values))\n",
        "        return Y\n",
        "fm = sgd.FMRegression(n_iter=1000, init_stdev=0.1, l2_reg_w=0,l2_reg_V=0, rank=2, step_size=0.1)\n",
        "fm = sgd.FMRegression(\n",
        "            n_iter=4743,\n",
        "            init_stdev=0.1,\n",
        "            rank=100,\n",
        "            l2_reg_w=0,\n",
        "            l2_reg_V=0,\n",
        "            step_size=0.1,\n",
        "        )\n",
        "pipe = make_pipeline(sparseNorm(),fm)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpcL4sOnDpJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "a= sp.sparse.csc_matrix(X2.values)\n",
        "sparseX = preprocessing.normalize(a)\n",
        "print(sparseX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhpXyReeJxyW",
        "colab_type": "code",
        "outputId": "f5a0789e-ee43-4db6-d010-b551a5fb2f88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "def optFMRegression(n_iter, init_stdev, rank, l2_reg_w, l2_reg_V,step_size):\n",
        "    cv = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "    score = cross_validate(\n",
        "            sgd.FMRegression(\n",
        "            n_iter=int(n_iter),\n",
        "            init_stdev=init_stdev,\n",
        "            rank=int(rank),\n",
        "            l2_reg_w=l2_reg_w,\n",
        "            l2_reg_V=l2_reg_V,\n",
        "            step_size=step_size,\n",
        "        ),\n",
        "        sparseX, y,\n",
        "        scoring='neg_mean_squared_error',\n",
        "        cv=cv,n_jobs=-1)\n",
        "    val = score['test_score'].mean()\n",
        "    return val\n",
        "score = optFMRegression(500,0,1,5,5,1)\n",
        "score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-inf"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFGIBmC3Go0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optFMRegression(n_iter, init_stdev, rank, l2_reg_w, l2_reg_V,step_size):\n",
        "    cv = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "    score = cross_validate(\n",
        "            sgd.FMRegression(\n",
        "            n_iter=int(n_iter),\n",
        "            init_stdev=init_stdev,\n",
        "            rank=int(rank),\n",
        "            l2_reg_w=l2_reg_w,\n",
        "            l2_reg_V=l2_reg_V,\n",
        "            step_size=step_size,\n",
        "        ),\n",
        "        sparseX, y,\n",
        "        scoring='neg_mean_squared_error',\n",
        "        cv=cv,n_jobs=-1)\n",
        "    val = score['test_score'].mean()\n",
        "    return val\n",
        "\n",
        "opt = BayesianOptimization(\n",
        "        optFMRegression,\n",
        "        {\n",
        "            'n_iter': (500,5000),\n",
        "            'init_stdev' : (0,20),\n",
        "            'rank' : (1,100),\n",
        "            'l2_reg_w' : (0.1,1),\n",
        "            'l2_reg_V' : (0,0.1),\n",
        "            'step_size' : (0.01,1)}\n",
        "    )\n",
        "opt.maximize(init_points=10,n_iter=100)\n",
        "opt.max"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq_P5Q9jblBp",
        "colab_type": "code",
        "outputId": "5f70b604-a3d0-4894-d25e-fba79916de1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "X2.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>20.3</th>\n",
              "      <th>21.3</th>\n",
              "      <th>22.3</th>\n",
              "      <th>23.3</th>\n",
              "      <th>24.3</th>\n",
              "      <th>25.3</th>\n",
              "      <th>26.3</th>\n",
              "      <th>27.3</th>\n",
              "      <th>28.3</th>\n",
              "      <th>29.3</th>\n",
              "      <th>30.3</th>\n",
              "      <th>31.3</th>\n",
              "      <th>32.3</th>\n",
              "      <th>33.3</th>\n",
              "      <th>34.3</th>\n",
              "      <th>35.3</th>\n",
              "      <th>36.3</th>\n",
              "      <th>37.3</th>\n",
              "      <th>38.3</th>\n",
              "      <th>39.3</th>\n",
              "      <th>40.3</th>\n",
              "      <th>41.3</th>\n",
              "      <th>42.3</th>\n",
              "      <th>43.3</th>\n",
              "      <th>44.3</th>\n",
              "      <th>45.3</th>\n",
              "      <th>46.3</th>\n",
              "      <th>47.3</th>\n",
              "      <th>48.3</th>\n",
              "      <th>49.3</th>\n",
              "      <th>50.3</th>\n",
              "      <th>51.3</th>\n",
              "      <th>52.3</th>\n",
              "      <th>53.3</th>\n",
              "      <th>54.3</th>\n",
              "      <th>55.3</th>\n",
              "      <th>56.3</th>\n",
              "      <th>57.3</th>\n",
              "      <th>58.3</th>\n",
              "      <th>59.3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5610 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  1  2  3  4  5  6  7  ...  52.3  53.3  54.3  55.3  56.3  57.3  58.3  59.3\n",
              "0  0  0  0  0  0  0  0  0  ...     0     0     1     0     0     0     0     0\n",
              "1  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0     0     0\n",
              "2  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0     0     0\n",
              "3  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0     0     0\n",
              "4  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0     0     0\n",
              "\n",
              "[5 rows x 5610 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpEk4_iSjbjH",
        "colab_type": "code",
        "outputId": "b4bb5b61-3f12-472a-bfd6-02dc3cb5dcf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "class sparseNorm(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        from sklearn import preprocessing\n",
        "        Y = preprocessing.normalize(sp.sparse.csc_matrix(X.values))\n",
        "        return Y\n",
        "fm = sgd.FMRegression(\n",
        "            n_iter=9943,\n",
        "            init_stdev=0.1,\n",
        "            rank=219,\n",
        "            l2_reg_w=0,\n",
        "            l2_reg_V=0.06454,\n",
        "            step_size=0.1,\n",
        "        )\n",
        "# fm = sgd.FMRegression(\n",
        "#             n_iter=4743,\n",
        "#             init_stdev=0.1,\n",
        "#             rank=100,\n",
        "#             l2_reg_w=0,\n",
        "#             l2_reg_V=0,\n",
        "#             step_size=0.1,\n",
        "#         )\n",
        "pipe = make_pipeline(sparseNorm(), fm)\n",
        "calcACC(pipe, X=X2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None test 1.2541720510947238 0.6584044433349703\n",
            "None train 1.0667708507173823 0.7909100866387624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwliXvKmQluE",
        "colab_type": "code",
        "outputId": "eb60066b-7917-443c-ee04-70124550b9bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def optFMRegression(n_iter,rank, l2_reg_w, l2_reg_V):\n",
        "    cv = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "    score = cross_validate(\n",
        "            sgd.FMRegression(\n",
        "            n_iter=n_iter,\n",
        "            init_stdev=0.1,\n",
        "            rank=int(rank),\n",
        "            l2_reg_w=l2_reg_w,\n",
        "            l2_reg_V=l2_reg_V,\n",
        "            step_size=0.1,\n",
        "        ),\n",
        "        sparseX, y,\n",
        "        scoring='neg_mean_squared_error',\n",
        "        cv=cv,n_jobs=-1)\n",
        "    val = score['test_score'].mean()\n",
        "    return val\n",
        "\n",
        "opt = BayesianOptimization(\n",
        "        optFMRegression,\n",
        "        {\n",
        "            'n_iter': (1000,10000),\n",
        "            'rank' : (1,1000),\n",
        "            'l2_reg_w':(0,10),\n",
        "            'l2_reg_V':(0,10),\n",
        "            }\n",
        "    )\n",
        "opt.maximize(init_points=10,n_iter=100)\n",
        "opt.max"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | l2_reg_V  | l2_reg_w  |  n_iter   |   rank    |\n",
            "-------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-2.645   \u001b[0m | \u001b[0m 5.552   \u001b[0m | \u001b[0m 8.434   \u001b[0m | \u001b[0m 3.456e+0\u001b[0m | \u001b[0m 51.34   \u001b[0m |\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m-2.728   \u001b[0m | \u001b[0m 7.015   \u001b[0m | \u001b[0m 8.225   \u001b[0m | \u001b[0m 9.659e+0\u001b[0m | \u001b[0m 611.9   \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m-2.664   \u001b[0m | \u001b[0m 7.405   \u001b[0m | \u001b[0m 9.113   \u001b[0m | \u001b[0m 4.448e+0\u001b[0m | \u001b[0m 299.7   \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m-2.676   \u001b[0m | \u001b[0m 5.971   \u001b[0m | \u001b[0m 6.375   \u001b[0m | \u001b[0m 5.296e+0\u001b[0m | \u001b[0m 180.9   \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m-2.885   \u001b[0m | \u001b[0m 6.361   \u001b[0m | \u001b[0m 8.665   \u001b[0m | \u001b[0m 5.821e+0\u001b[0m | \u001b[0m 905.3   \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m-2.821   \u001b[0m | \u001b[0m 2.463   \u001b[0m | \u001b[0m 5.221   \u001b[0m | \u001b[0m 5.173e+0\u001b[0m | \u001b[0m 982.6   \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-2.879   \u001b[0m | \u001b[0m 7.909   \u001b[0m | \u001b[0m 5.632   \u001b[0m | \u001b[0m 9.255e+0\u001b[0m | \u001b[0m 486.2   \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m-2.703   \u001b[0m | \u001b[0m 1.415   \u001b[0m | \u001b[0m 6.475   \u001b[0m | \u001b[0m 2.269e+0\u001b[0m | \u001b[0m 18.97   \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m-2.73    \u001b[0m | \u001b[0m 4.203   \u001b[0m | \u001b[0m 4.202   \u001b[0m | \u001b[0m 1.961e+0\u001b[0m | \u001b[0m 151.7   \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m-2.748   \u001b[0m | \u001b[0m 6.82    \u001b[0m | \u001b[0m 3.247   \u001b[0m | \u001b[0m 6.016e+0\u001b[0m | \u001b[0m 73.06   \u001b[0m |\n",
            "| \u001b[95m 11      \u001b[0m | \u001b[95m-1.66    \u001b[0m | \u001b[95m 1.736e-0\u001b[0m | \u001b[95m 2.189e-0\u001b[0m | \u001b[95m 1e+04   \u001b[0m | \u001b[95m 1.0     \u001b[0m |\n",
            "| \u001b[0m 12      \u001b[0m | \u001b[0m-2.756   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1e+04   \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m-2.766   \u001b[0m | \u001b[0m 1.098   \u001b[0m | \u001b[0m 3.967   \u001b[0m | \u001b[0m 5.826e+0\u001b[0m | \u001b[0m 937.9   \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m-2.755   \u001b[0m | \u001b[0m 2.843   \u001b[0m | \u001b[0m 3.75    \u001b[0m | \u001b[0m 3.72e+03\u001b[0m | \u001b[0m 691.5   \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m-2.691   \u001b[0m | \u001b[0m 5.167   \u001b[0m | \u001b[0m 6.808   \u001b[0m | \u001b[0m 3.445e+0\u001b[0m | \u001b[0m 844.5   \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m-2.548   \u001b[0m | \u001b[0m 4.179   \u001b[0m | \u001b[0m 2.088   \u001b[0m | \u001b[0m 4.147e+0\u001b[0m | \u001b[0m 719.1   \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m-2.693   \u001b[0m | \u001b[0m 3.221   \u001b[0m | \u001b[0m 6.403   \u001b[0m | \u001b[0m 7.882e+0\u001b[0m | \u001b[0m 30.81   \u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m-2.885   \u001b[0m | \u001b[0m 6.765   \u001b[0m | \u001b[0m 0.8571  \u001b[0m | \u001b[0m 1.351e+0\u001b[0m | \u001b[0m 768.1   \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m-2.645   \u001b[0m | \u001b[0m 4.61    \u001b[0m | \u001b[0m 2.981   \u001b[0m | \u001b[0m 4.143e+0\u001b[0m | \u001b[0m 717.8   \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m-2.492   \u001b[0m | \u001b[0m 2.107   \u001b[0m | \u001b[0m 1.054   \u001b[0m | \u001b[0m 9.986e+0\u001b[0m | \u001b[0m 39.56   \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m-2.67    \u001b[0m | \u001b[0m 0.2611  \u001b[0m | \u001b[0m 3.185   \u001b[0m | \u001b[0m 9.955e+0\u001b[0m | \u001b[0m 13.02   \u001b[0m |\n",
            "| \u001b[95m 22      \u001b[0m | \u001b[95m-1.655   \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 4.193e+0\u001b[0m | \u001b[95m 735.7   \u001b[0m |\n",
            "| \u001b[95m 23      \u001b[0m | \u001b[95m-1.626   \u001b[0m | \u001b[95m 4.205   \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 4.201e+0\u001b[0m | \u001b[95m 704.6   \u001b[0m |\n",
            "| \u001b[0m 24      \u001b[0m | \u001b[0m-2.987   \u001b[0m | \u001b[0m 6.665   \u001b[0m | \u001b[0m 4.089   \u001b[0m | \u001b[0m 4.238e+0\u001b[0m | \u001b[0m 733.9   \u001b[0m |\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m-2.67    \u001b[0m | \u001b[0m 1.987   \u001b[0m | \u001b[0m 9.248   \u001b[0m | \u001b[0m 4.201e+0\u001b[0m | \u001b[0m 667.3   \u001b[0m |\n",
            "| \u001b[0m 26      \u001b[0m | \u001b[0m-2.679   \u001b[0m | \u001b[0m 8.536   \u001b[0m | \u001b[0m 6.423   \u001b[0m | \u001b[0m 4.171e+0\u001b[0m | \u001b[0m 765.6   \u001b[0m |\n",
            "| \u001b[0m 27      \u001b[0m | \u001b[0m-2.706   \u001b[0m | \u001b[0m 3.676   \u001b[0m | \u001b[0m 4.166   \u001b[0m | \u001b[0m 2.889e+0\u001b[0m | \u001b[0m 724.7   \u001b[0m |\n",
            "| \u001b[0m 28      \u001b[0m | \u001b[0m-2.739   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 7.339   \u001b[0m | \u001b[0m 6.975e+0\u001b[0m | \u001b[0m 973.2   \u001b[0m |\n",
            "| \u001b[0m 29      \u001b[0m | \u001b[0m-2.755   \u001b[0m | \u001b[0m 8.961   \u001b[0m | \u001b[0m 6.158   \u001b[0m | \u001b[0m 2.385e+0\u001b[0m | \u001b[0m 509.6   \u001b[0m |\n",
            "| \u001b[0m 30      \u001b[0m | \u001b[0m-2.703   \u001b[0m | \u001b[0m 6.929   \u001b[0m | \u001b[0m 7.971   \u001b[0m | \u001b[0m 1.142e+0\u001b[0m | \u001b[0m 115.4   \u001b[0m |\n",
            "| \u001b[0m 31      \u001b[0m | \u001b[0m-2.649   \u001b[0m | \u001b[0m 0.9459  \u001b[0m | \u001b[0m 7.008   \u001b[0m | \u001b[0m 8.704e+0\u001b[0m | \u001b[0m 833.3   \u001b[0m |\n",
            "| \u001b[0m 32      \u001b[0m | \u001b[0m-3.24    \u001b[0m | \u001b[0m 3.825   \u001b[0m | \u001b[0m 2.301   \u001b[0m | \u001b[0m 6.883e+0\u001b[0m | \u001b[0m 155.2   \u001b[0m |\n",
            "| \u001b[0m 33      \u001b[0m | \u001b[0m-2.151   \u001b[0m | \u001b[0m 2.756   \u001b[0m | \u001b[0m 0.2703  \u001b[0m | \u001b[0m 9.997e+0\u001b[0m | \u001b[0m 164.4   \u001b[0m |\n",
            "| \u001b[0m 34      \u001b[0m | \u001b[0m-2.292   \u001b[0m | \u001b[0m 3.666   \u001b[0m | \u001b[0m 0.4978  \u001b[0m | \u001b[0m 9.977e+0\u001b[0m | \u001b[0m 211.5   \u001b[0m |\n",
            "| \u001b[0m 35      \u001b[0m | \u001b[0m-2.699   \u001b[0m | \u001b[0m 3.277   \u001b[0m | \u001b[0m 8.414   \u001b[0m | \u001b[0m 9.94e+03\u001b[0m | \u001b[0m 159.3   \u001b[0m |\n",
            "| \u001b[0m 36      \u001b[0m | \u001b[0m-2.814   \u001b[0m | \u001b[0m 4.649   \u001b[0m | \u001b[0m 9.865   \u001b[0m | \u001b[0m 9.997e+0\u001b[0m | \u001b[0m 115.7   \u001b[0m |\n",
            "| \u001b[0m 37      \u001b[0m | \u001b[0m-1.843   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1e+04   \u001b[0m | \u001b[0m 271.7   \u001b[0m |\n",
            "| \u001b[0m 38      \u001b[0m | \u001b[0m-2.942   \u001b[0m | \u001b[0m 7.689   \u001b[0m | \u001b[0m 9.307   \u001b[0m | \u001b[0m 9.958e+0\u001b[0m | \u001b[0m 282.7   \u001b[0m |\n",
            "| \u001b[0m 39      \u001b[0m | \u001b[0m-2.726   \u001b[0m | \u001b[0m 2.885   \u001b[0m | \u001b[0m 3.007   \u001b[0m | \u001b[0m 9.995e+0\u001b[0m | \u001b[0m 328.9   \u001b[0m |\n",
            "| \u001b[0m 40      \u001b[0m | \u001b[0m-2.494   \u001b[0m | \u001b[0m 7.695   \u001b[0m | \u001b[0m 0.6015  \u001b[0m | \u001b[0m 7.393e+0\u001b[0m | \u001b[0m 615.5   \u001b[0m |\n",
            "| \u001b[0m 41      \u001b[0m | \u001b[0m-3.118   \u001b[0m | \u001b[0m 4.764   \u001b[0m | \u001b[0m 2.573   \u001b[0m | \u001b[0m 7.443e+0\u001b[0m | \u001b[0m 678.6   \u001b[0m |\n",
            "| \u001b[0m 42      \u001b[0m | \u001b[0m-2.544   \u001b[0m | \u001b[0m 0.1861  \u001b[0m | \u001b[0m 4.849   \u001b[0m | \u001b[0m 7.345e+0\u001b[0m | \u001b[0m 557.4   \u001b[0m |\n",
            "| \u001b[95m 43      \u001b[0m | \u001b[95m-1.604   \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 7.429e+0\u001b[0m | \u001b[95m 542.9   \u001b[0m |\n",
            "| \u001b[0m 44      \u001b[0m | \u001b[0m-2.665   \u001b[0m | \u001b[0m 9.436   \u001b[0m | \u001b[0m 2.917   \u001b[0m | \u001b[0m 7.421e+0\u001b[0m | \u001b[0m 504.3   \u001b[0m |\n",
            "| \u001b[0m 45      \u001b[0m | \u001b[0m-3.093   \u001b[0m | \u001b[0m 1.609   \u001b[0m | \u001b[0m 5.888   \u001b[0m | \u001b[0m 7.459e+0\u001b[0m | \u001b[0m 568.2   \u001b[0m |\n",
            "| \u001b[0m 46      \u001b[0m | \u001b[0m-2.688   \u001b[0m | \u001b[0m 9.13    \u001b[0m | \u001b[0m 9.919   \u001b[0m | \u001b[0m 7.404e+0\u001b[0m | \u001b[0m 556.5   \u001b[0m |\n",
            "| \u001b[0m 47      \u001b[0m | \u001b[0m-2.676   \u001b[0m | \u001b[0m 5.719   \u001b[0m | \u001b[0m 4.173   \u001b[0m | \u001b[0m 4.181e+0\u001b[0m | \u001b[0m 712.9   \u001b[0m |\n",
            "| \u001b[0m 48      \u001b[0m | \u001b[0m-2.671   \u001b[0m | \u001b[0m 8.352   \u001b[0m | \u001b[0m 7.202   \u001b[0m | \u001b[0m 4.208e+0\u001b[0m | \u001b[0m 726.6   \u001b[0m |\n",
            "| \u001b[0m 49      \u001b[0m | \u001b[0m-3.099   \u001b[0m | \u001b[0m 4.834   \u001b[0m | \u001b[0m 9.203   \u001b[0m | \u001b[0m 7.438e+0\u001b[0m | \u001b[0m 530.9   \u001b[0m |\n",
            "| \u001b[0m 50      \u001b[0m | \u001b[0m-2.365   \u001b[0m | \u001b[0m 7.935   \u001b[0m | \u001b[0m 0.3249  \u001b[0m | \u001b[0m 7.431e+0\u001b[0m | \u001b[0m 559.5   \u001b[0m |\n",
            "| \u001b[0m 51      \u001b[0m | \u001b[0m-2.291   \u001b[0m | \u001b[0m 0.4433  \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 4.202e+0\u001b[0m | \u001b[0m 755.2   \u001b[0m |\n",
            "| \u001b[0m 52      \u001b[0m | \u001b[0m-2.705   \u001b[0m | \u001b[0m 9.696   \u001b[0m | \u001b[0m 9.074   \u001b[0m | \u001b[0m 4.214e+0\u001b[0m | \u001b[0m 692.3   \u001b[0m |\n",
            "| \u001b[0m 53      \u001b[0m | \u001b[0m-2.799   \u001b[0m | \u001b[0m 1.779   \u001b[0m | \u001b[0m 6.086   \u001b[0m | \u001b[0m 9.995e+0\u001b[0m | \u001b[0m 250.9   \u001b[0m |\n",
            "| \u001b[0m 54      \u001b[0m | \u001b[0m-2.796   \u001b[0m | \u001b[0m 1.183   \u001b[0m | \u001b[0m 4.364   \u001b[0m | \u001b[0m 9.992e+0\u001b[0m | \u001b[0m 290.9   \u001b[0m |\n",
            "| \u001b[0m 55      \u001b[0m | \u001b[0m-2.678   \u001b[0m | \u001b[0m 3.677   \u001b[0m | \u001b[0m 7.863   \u001b[0m | \u001b[0m 9.978e+0\u001b[0m | \u001b[0m 184.3   \u001b[0m |\n",
            "| \u001b[0m 56      \u001b[0m | \u001b[0m-2.61    \u001b[0m | \u001b[0m 4.58    \u001b[0m | \u001b[0m 2.732   \u001b[0m | \u001b[0m 7.413e+0\u001b[0m | \u001b[0m 534.7   \u001b[0m |\n",
            "| \u001b[95m 57      \u001b[0m | \u001b[95m-1.583   \u001b[0m | \u001b[95m 0.06455 \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 9.943e+0\u001b[0m | \u001b[95m 219.4   \u001b[0m |\n",
            "| \u001b[0m 58      \u001b[0m | \u001b[0m-1.779   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 9.923e+0\u001b[0m | \u001b[0m 217.7   \u001b[0m |\n",
            "| \u001b[0m 59      \u001b[0m | \u001b[0m-2.679   \u001b[0m | \u001b[0m 5.746   \u001b[0m | \u001b[0m 4.351   \u001b[0m | \u001b[0m 9.933e+0\u001b[0m | \u001b[0m 240.7   \u001b[0m |\n",
            "| \u001b[0m 60      \u001b[0m | \u001b[0m-2.689   \u001b[0m | \u001b[0m 2.046   \u001b[0m | \u001b[0m 8.953   \u001b[0m | \u001b[0m 9.934e+0\u001b[0m | \u001b[0m 198.1   \u001b[0m |\n",
            "| \u001b[0m 61      \u001b[0m | \u001b[0m-2.856   \u001b[0m | \u001b[0m 6.223   \u001b[0m | \u001b[0m 3.353   \u001b[0m | \u001b[0m 9.894e+0\u001b[0m | \u001b[0m 215.8   \u001b[0m |\n",
            "| \u001b[0m 62      \u001b[0m | \u001b[0m-2.718   \u001b[0m | \u001b[0m 4.617   \u001b[0m | \u001b[0m 9.688   \u001b[0m | \u001b[0m 7.343e+0\u001b[0m | \u001b[0m 627.0   \u001b[0m |\n",
            "| \u001b[0m 63      \u001b[0m | \u001b[0m-2.688   \u001b[0m | \u001b[0m 2.116   \u001b[0m | \u001b[0m 5.604   \u001b[0m | \u001b[0m 7.3e+03 \u001b[0m | \u001b[0m 519.7   \u001b[0m |\n",
            "| \u001b[0m 64      \u001b[0m | \u001b[0m-2.739   \u001b[0m | \u001b[0m 9.865   \u001b[0m | \u001b[0m 2.991   \u001b[0m | \u001b[0m 7.397e+0\u001b[0m | \u001b[0m 444.2   \u001b[0m |\n",
            "| \u001b[0m 65      \u001b[0m | \u001b[0m-2.987   \u001b[0m | \u001b[0m 8.456   \u001b[0m | \u001b[0m 2.696   \u001b[0m | \u001b[0m 4.634e+0\u001b[0m | \u001b[0m 996.5   \u001b[0m |\n",
            "| \u001b[0m 66      \u001b[0m | \u001b[0m-2.807   \u001b[0m | \u001b[0m 0.4902  \u001b[0m | \u001b[0m 9.892   \u001b[0m | \u001b[0m 1.132e+0\u001b[0m | \u001b[0m 418.4   \u001b[0m |\n",
            "| \u001b[0m 67      \u001b[0m | \u001b[0m-2.66    \u001b[0m | \u001b[0m 2.73    \u001b[0m | \u001b[0m 3.862   \u001b[0m | \u001b[0m 6.29e+03\u001b[0m | \u001b[0m 547.6   \u001b[0m |\n",
            "| \u001b[0m 68      \u001b[0m | \u001b[0m-2.709   \u001b[0m | \u001b[0m 4.568   \u001b[0m | \u001b[0m 6.687   \u001b[0m | \u001b[0m 6.391e+0\u001b[0m | \u001b[0m 206.6   \u001b[0m |\n",
            "| \u001b[0m 69      \u001b[0m | \u001b[0m-2.608   \u001b[0m | \u001b[0m 7.511   \u001b[0m | \u001b[0m 1.968   \u001b[0m | \u001b[0m 2.239e+0\u001b[0m | \u001b[0m 997.0   \u001b[0m |\n",
            "| \u001b[0m 70      \u001b[0m | \u001b[0m-1.709   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 9.961e+0\u001b[0m | \u001b[0m 231.9   \u001b[0m |\n",
            "| \u001b[0m 71      \u001b[0m | \u001b[0m-2.686   \u001b[0m | \u001b[0m 2.305   \u001b[0m | \u001b[0m 5.001   \u001b[0m | \u001b[0m 1.537e+0\u001b[0m | \u001b[0m 229.8   \u001b[0m |\n",
            "| \u001b[0m 72      \u001b[0m | \u001b[0m-2.729   \u001b[0m | \u001b[0m 8.739   \u001b[0m | \u001b[0m 8.876   \u001b[0m | \u001b[0m 2.752e+0\u001b[0m | \u001b[0m 181.1   \u001b[0m |\n",
            "| \u001b[0m 73      \u001b[0m | \u001b[0m-3.037   \u001b[0m | \u001b[0m 4.226   \u001b[0m | \u001b[0m 8.026   \u001b[0m | \u001b[0m 1.821e+0\u001b[0m | \u001b[0m 787.6   \u001b[0m |\n",
            "| \u001b[0m 74      \u001b[0m | \u001b[0m-2.686   \u001b[0m | \u001b[0m 4.016   \u001b[0m | \u001b[0m 3.772   \u001b[0m | \u001b[0m 2.182e+0\u001b[0m | \u001b[0m 904.9   \u001b[0m |\n",
            "| \u001b[0m 75      \u001b[0m | \u001b[0m-2.608   \u001b[0m | \u001b[0m 2.36    \u001b[0m | \u001b[0m 3.753   \u001b[0m | \u001b[0m 2.34e+03\u001b[0m | \u001b[0m 990.7   \u001b[0m |\n",
            "| \u001b[0m 76      \u001b[0m | \u001b[0m-2.471   \u001b[0m | \u001b[0m 8.594   \u001b[0m | \u001b[0m 0.664   \u001b[0m | \u001b[0m 2.41e+03\u001b[0m | \u001b[0m 924.7   \u001b[0m |\n",
            "| \u001b[0m 77      \u001b[0m | \u001b[0m-2.666   \u001b[0m | \u001b[0m 5.023   \u001b[0m | \u001b[0m 5.676   \u001b[0m | \u001b[0m 9.665e+0\u001b[0m | \u001b[0m 929.9   \u001b[0m |\n",
            "| \u001b[0m 78      \u001b[0m | \u001b[0m-2.678   \u001b[0m | \u001b[0m 8.887   \u001b[0m | \u001b[0m 4.765   \u001b[0m | \u001b[0m 2.46e+03\u001b[0m | \u001b[0m 915.8   \u001b[0m |\n",
            "| \u001b[0m 79      \u001b[0m | \u001b[0m-3.193   \u001b[0m | \u001b[0m 5.982   \u001b[0m | \u001b[0m 7.395   \u001b[0m | \u001b[0m 2.368e+0\u001b[0m | \u001b[0m 895.1   \u001b[0m |\n",
            "| \u001b[0m 80      \u001b[0m | \u001b[0m-2.672   \u001b[0m | \u001b[0m 9.235   \u001b[0m | \u001b[0m 6.619   \u001b[0m | \u001b[0m 2.401e+0\u001b[0m | \u001b[0m 975.0   \u001b[0m |\n",
            "| \u001b[0m 81      \u001b[0m | \u001b[0m-2.751   \u001b[0m | \u001b[0m 7.872   \u001b[0m | \u001b[0m 9.339   \u001b[0m | \u001b[0m 4.892e+0\u001b[0m | \u001b[0m 519.4   \u001b[0m |\n",
            "| \u001b[0m 82      \u001b[0m | \u001b[0m-2.697   \u001b[0m | \u001b[0m 5.572   \u001b[0m | \u001b[0m 4.169   \u001b[0m | \u001b[0m 9.086e+0\u001b[0m | \u001b[0m 827.7   \u001b[0m |\n",
            "| \u001b[0m 83      \u001b[0m | \u001b[0m-2.675   \u001b[0m | \u001b[0m 9.604   \u001b[0m | \u001b[0m 8.93    \u001b[0m | \u001b[0m 8.453e+0\u001b[0m | \u001b[0m 339.4   \u001b[0m |\n",
            "| \u001b[0m 84      \u001b[0m | \u001b[0m-2.705   \u001b[0m | \u001b[0m 3.506   \u001b[0m | \u001b[0m 7.557   \u001b[0m | \u001b[0m 4.115e+0\u001b[0m | \u001b[0m 145.1   \u001b[0m |\n",
            "| \u001b[0m 85      \u001b[0m | \u001b[0m-2.784   \u001b[0m | \u001b[0m 2.774   \u001b[0m | \u001b[0m 7.46    \u001b[0m | \u001b[0m 5.654e+0\u001b[0m | \u001b[0m 536.9   \u001b[0m |\n",
            "| \u001b[0m 86      \u001b[0m | \u001b[0m-2.724   \u001b[0m | \u001b[0m 7.228   \u001b[0m | \u001b[0m 6.247   \u001b[0m | \u001b[0m 7.958e+0\u001b[0m | \u001b[0m 854.3   \u001b[0m |\n",
            "| \u001b[0m 87      \u001b[0m | \u001b[0m-2.749   \u001b[0m | \u001b[0m 5.759   \u001b[0m | \u001b[0m 8.033   \u001b[0m | \u001b[0m 4.929e+0\u001b[0m | \u001b[0m 30.22   \u001b[0m |\n",
            "| \u001b[0m 88      \u001b[0m | \u001b[0m-2.683   \u001b[0m | \u001b[0m 0.3214  \u001b[0m | \u001b[0m 9.343   \u001b[0m | \u001b[0m 8.881e+0\u001b[0m | \u001b[0m 294.2   \u001b[0m |\n",
            "| \u001b[0m 89      \u001b[0m | \u001b[0m-2.865   \u001b[0m | \u001b[0m 8.659   \u001b[0m | \u001b[0m 1.609   \u001b[0m | \u001b[0m 6.868e+0\u001b[0m | \u001b[0m 541.9   \u001b[0m |\n",
            "| \u001b[0m 90      \u001b[0m | \u001b[0m-2.663   \u001b[0m | \u001b[0m 3.313   \u001b[0m | \u001b[0m 8.242   \u001b[0m | \u001b[0m 2.169e+0\u001b[0m | \u001b[0m 997.5   \u001b[0m |\n",
            "| \u001b[0m 91      \u001b[0m | \u001b[0m-2.604   \u001b[0m | \u001b[0m 7.782   \u001b[0m | \u001b[0m 2.107   \u001b[0m | \u001b[0m 6.551e+0\u001b[0m | \u001b[0m 841.0   \u001b[0m |\n",
            "| \u001b[0m 92      \u001b[0m | \u001b[0m-2.713   \u001b[0m | \u001b[0m 3.807   \u001b[0m | \u001b[0m 9.024   \u001b[0m | \u001b[0m 6.546e+0\u001b[0m | \u001b[0m 911.3   \u001b[0m |\n",
            "| \u001b[0m 93      \u001b[0m | \u001b[0m-3.095   \u001b[0m | \u001b[0m 6.845   \u001b[0m | \u001b[0m 3.216   \u001b[0m | \u001b[0m 6.522e+0\u001b[0m | \u001b[0m 777.4   \u001b[0m |\n",
            "| \u001b[0m 94      \u001b[0m | \u001b[0m-2.654   \u001b[0m | \u001b[0m 4.022   \u001b[0m | \u001b[0m 5.476   \u001b[0m | \u001b[0m 6.619e+0\u001b[0m | \u001b[0m 832.7   \u001b[0m |\n",
            "| \u001b[0m 95      \u001b[0m | \u001b[0m-2.649   \u001b[0m | \u001b[0m 7.096   \u001b[0m | \u001b[0m 5.121   \u001b[0m | \u001b[0m 7.841e+0\u001b[0m | \u001b[0m 458.7   \u001b[0m |\n",
            "| \u001b[0m 96      \u001b[0m | \u001b[0m-2.89    \u001b[0m | \u001b[0m 8.321   \u001b[0m | \u001b[0m 8.99    \u001b[0m | \u001b[0m 3.117e+0\u001b[0m | \u001b[0m 214.8   \u001b[0m |\n",
            "| \u001b[0m 97      \u001b[0m | \u001b[0m-2.824   \u001b[0m | \u001b[0m 1.576   \u001b[0m | \u001b[0m 7.748   \u001b[0m | \u001b[0m 9.319e+0\u001b[0m | \u001b[0m 110.4   \u001b[0m |\n",
            "| \u001b[0m 98      \u001b[0m | \u001b[0m-2.644   \u001b[0m | \u001b[0m 6.232   \u001b[0m | \u001b[0m 4.773   \u001b[0m | \u001b[0m 7.255e+0\u001b[0m | \u001b[0m 89.15   \u001b[0m |\n",
            "| \u001b[0m 99      \u001b[0m | \u001b[0m-2.788   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 2.268e+0\u001b[0m | \u001b[0m 936.3   \u001b[0m |\n",
            "| \u001b[0m 100     \u001b[0m | \u001b[0m-2.243   \u001b[0m | \u001b[0m 4.503   \u001b[0m | \u001b[0m 0.354   \u001b[0m | \u001b[0m 8.677e+0\u001b[0m | \u001b[0m 8.522   \u001b[0m |\n",
            "| \u001b[0m 101     \u001b[0m | \u001b[0m-2.66    \u001b[0m | \u001b[0m 8.569   \u001b[0m | \u001b[0m 3.415   \u001b[0m | \u001b[0m 8.641e+0\u001b[0m | \u001b[0m 18.69   \u001b[0m |\n",
            "| \u001b[0m 102     \u001b[0m | \u001b[0m-2.703   \u001b[0m | \u001b[0m 1.458   \u001b[0m | \u001b[0m 7.776   \u001b[0m | \u001b[0m 8.707e+0\u001b[0m | \u001b[0m 34.15   \u001b[0m |\n",
            "| \u001b[0m 103     \u001b[0m | \u001b[0m-2.687   \u001b[0m | \u001b[0m 3.06    \u001b[0m | \u001b[0m 5.631   \u001b[0m | \u001b[0m 5.265e+0\u001b[0m | \u001b[0m 607.7   \u001b[0m |\n",
            "| \u001b[0m 104     \u001b[0m | \u001b[0m-2.656   \u001b[0m | \u001b[0m 4.739   \u001b[0m | \u001b[0m 9.345   \u001b[0m | \u001b[0m 1.034e+0\u001b[0m | \u001b[0m 980.6   \u001b[0m |\n",
            "| \u001b[0m 105     \u001b[0m | \u001b[0m-2.576   \u001b[0m | \u001b[0m 1.429   \u001b[0m | \u001b[0m 1.34    \u001b[0m | \u001b[0m 3.444e+0\u001b[0m | \u001b[0m 450.4   \u001b[0m |\n",
            "| \u001b[0m 106     \u001b[0m | \u001b[0m-3.262   \u001b[0m | \u001b[0m 2.551   \u001b[0m | \u001b[0m 7.399   \u001b[0m | \u001b[0m 3.503e+0\u001b[0m | \u001b[0m 432.0   \u001b[0m |\n",
            "| \u001b[0m 107     \u001b[0m | \u001b[0m-2.899   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 9.955e+0\u001b[0m | \u001b[0m 219.7   \u001b[0m |\n",
            "| \u001b[0m 108     \u001b[0m | \u001b[0m-2.683   \u001b[0m | \u001b[0m 6.371   \u001b[0m | \u001b[0m 9.032   \u001b[0m | \u001b[0m 3.407e+0\u001b[0m | \u001b[0m 489.1   \u001b[0m |\n",
            "| \u001b[0m 109     \u001b[0m | \u001b[0m-2.483   \u001b[0m | \u001b[0m 2.218   \u001b[0m | \u001b[0m 0.742   \u001b[0m | \u001b[0m 3.399e+0\u001b[0m | \u001b[0m 416.8   \u001b[0m |\n",
            "| \u001b[0m 110     \u001b[0m | \u001b[0m-2.717   \u001b[0m | \u001b[0m 7.225   \u001b[0m | \u001b[0m 8.933   \u001b[0m | \u001b[0m 3.355e+0\u001b[0m | \u001b[0m 405.6   \u001b[0m |\n",
            "=========================================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'params': {'l2_reg_V': 0.06454808266719353,\n",
              "  'l2_reg_w': 0.0,\n",
              "  'n_iter': 9943.385736317281,\n",
              "  'rank': 219.3830156897833},\n",
              " 'target': -1.5833112158687874}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkVXJozvIWZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = BayesianOptimization(\n",
        "        optFMRegression,\n",
        "        {\n",
        "            'n_iter':(500,5000),\n",
        "            'init_stdev':(0,20),\n",
        "            'rank':(1,100),\n",
        "            'l2_reg_w':(0,10),\n",
        "            'l2_reg_V':(0,10),\n",
        "            'step_size':(0.01,1)\n",
        "        }\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6gbpBvutd3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class addDim(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        Y = np.expand_dims(X, axis=2)\n",
        "        return Y\n",
        "def NN_model(data= X):\n",
        "  #data = np.expand_dims(data, axis=0)\n",
        "  #data = np.reshape(X_train.values, (-1, 13, 1))\n",
        "  inputs = Input(((data.shape[1],1)))\n",
        "#   print(inputs)\n",
        "  x = Conv1D(1,1,dilation_rate=2,padding=\"same\", activation=\"relu\")(inputs)\n",
        "  #x = BatchNormalization()(x)\n",
        "  #x = Conv1D(1,1,dilation_rate=2,padding=\"same\", activation=\"relu\")(x)\n",
        "\n",
        "  #x = MaxPooling1D(1, padding='same')(x)\n",
        "  #x = Conv1D(1,1,dilation_rate=2,padding=\"same\", activation=\"relu\")(x)\n",
        "  #x = MaxPooling1D(2, padding='same')(x)\n",
        "  #x = Conv1D(16,2,dilation_rate=2,padding=\"same\", activation=\"relu\")(x)\n",
        "  #x = MaxPooling1D(2, padding='same')(x)\n",
        "  #predictions = Conv1D(1,2,dilation_rate=2,padding=\"same\", activation=\"relu\")(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "  #x = Dense(2048, activation=\"relu\")(x)\n",
        "#   x = Dropout(0.5)(x)\n",
        "#   x = Dense(2048, activation=\"relu\")(x)\n",
        "#   x = Dense(2048, activation=\"relu\")(x)\n",
        "#   x = Dense(512, activation=\"relu\")(x)\n",
        "#   x = Dense(256, activation=\"relu\")(x)\n",
        "#   x = Dense(64, activation=\"relu\")(x)\n",
        "#   x = Dense(16, activation=\"relu\")(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  x  = Dense(2048, activation=\"relu\")(x)\n",
        "  predictions = Dense(1)(x)\n",
        "  model = Model(inputs=inputs, outputs=predictions)\n",
        "  model.compile(optimizer=\"adam\",loss='mean_squared_error')\n",
        "  model.summary()\n",
        "  return model\n",
        "#nn_model = NN_model(X_train)\n",
        "nn = KerasRegressor(build_fn=NN_model, epochs=100, batch_size=100, verbose=0)\n",
        "nn = make_pipeline(addDim(),nn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdsgzNVw0xHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class addDim(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        Y = np.expand_dims(X, axis=2)\n",
        "        return Y\n",
        "def LSTM_model(data= X):\n",
        "  #data = np.expand_dims(data, axis=0)\n",
        "  #data = np.reshape(X_train.values, (-1, 13, 1))\n",
        "  inputs = Input(((data.shape[1],1)))\n",
        "#   print(inputs)\n",
        "#   x = Conv1D(1,1,dilation_rate=2,padding=\"same\", activation=\"relu\")(inputs)\n",
        "#   x = BatchNormalization()(x)\n",
        "  #x = Conv1D(1,1,dilation_rate=2,padding=\"same\", activation=\"relu\")(x)\n",
        "  x = CuDNNLSTM(32,return_sequences=True)(inputs)\n",
        "  x = CuDNNLSTM(64,return_sequences=True)(x)\n",
        "  #x = MaxPooling1D(1, padding='same')(x)\n",
        "  #x = Conv1D(1,1,dilation_rate=2,padding=\"same\", activation=\"relu\")(x)\n",
        "  #x = MaxPooling1D(2, padding='same')(x)\n",
        "  #x = Conv1D(16,2,dilation_rate=2,padding=\"same\", activation=\"relu\")(x)\n",
        "  #x = MaxPooling1D(2, padding='same')(x)\n",
        "  #predictions = Conv1D(1,2,dilation_rate=2,padding=\"same\", activation=\"relu\")(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "  #x = Dense(2048, activation=\"relu\")(x)\n",
        "#   x = Dropout(0.5)(x)\n",
        "#   x = Dense(2048, activation=\"relu\")(x)\n",
        "#   x = Dense(2048, activation=\"relu\")(x)\n",
        "#   x = Dense(512, activation=\"relu\")(x)\n",
        "#   x = Dense(256, activation=\"relu\")(x)\n",
        "#   x = Dense(64, activation=\"relu\")(x)\n",
        "#   x = Dense(16, activation=\"relu\")(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "  x  = Dense(128, activation=\"relu\")(x)\n",
        "  predictions = Dense(1)(x)\n",
        "  model = Model(inputs=inputs, outputs=predictions)\n",
        "  model.compile(optimizer=\"adam\",loss='mean_squared_error')\n",
        "  model.summary()\n",
        "  return model\n",
        "nn = KerasRegressor(build_fn=LSTM_model, epochs=100, batch_size=100, verbose=0)\n",
        "lstm = make_pipeline(addDim(),nn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNPmnpM0XSOy",
        "colab_type": "code",
        "outputId": "76a4ec2d-1f92-400b-99da-b413e718a66a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "calcACC(lstm,X=X2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0626 15:45:38.144906 139993621567360 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 5610, 1)]         0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm (CuDNNLSTM)       (None, 5610, 32)          4480      \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)     (None, 5610, 64)          25088     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               45957248  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 45,986,945\n",
            "Trainable params: 45,986,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 5610, 1)]         0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_2 (CuDNNLSTM)     (None, 5610, 32)          4480      \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_3 (CuDNNLSTM)     (None, 5610, 64)          25088     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               45957248  \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 45,986,945\n",
            "Trainable params: 45,986,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 5610, 1)]         0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_4 (CuDNNLSTM)     (None, 5610, 32)          4480      \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_5 (CuDNNLSTM)     (None, 5610, 64)          25088     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               45957248  \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 45,986,945\n",
            "Trainable params: 45,986,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 5610, 1)]         0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_6 (CuDNNLSTM)     (None, 5610, 32)          4480      \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_7 (CuDNNLSTM)     (None, 5610, 64)          25088     \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               45957248  \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 45,986,945\n",
            "Trainable params: 45,986,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 5610, 1)]         0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_8 (CuDNNLSTM)     (None, 5610, 32)          4480      \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_9 (CuDNNLSTM)     (None, 5610, 64)          25088     \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               45957248  \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 45,986,945\n",
            "Trainable params: 45,986,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 5610, 1)]         0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_10 (CuDNNLSTM)    (None, 5610, 32)          4480      \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_11 (CuDNNLSTM)    (None, 5610, 64)          25088     \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               45957248  \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 45,986,945\n",
            "Trainable params: 45,986,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 5610, 1)]         0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_12 (CuDNNLSTM)    (None, 5610, 32)          4480      \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_13 (CuDNNLSTM)    (None, 5610, 64)          25088     \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               45957248  \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 45,986,945\n",
            "Trainable params: 45,986,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 5610, 1)]         0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_14 (CuDNNLSTM)    (None, 5610, 32)          4480      \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_15 (CuDNNLSTM)    (None, 5610, 64)          25088     \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 128)               45957248  \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 45,986,945\n",
            "Trainable params: 45,986,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 5610, 1)]         0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_16 (CuDNNLSTM)    (None, 5610, 32)          4480      \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_17 (CuDNNLSTM)    (None, 5610, 64)          25088     \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               45957248  \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 45,986,945\n",
            "Trainable params: 45,986,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 5610, 1)]         0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_18 (CuDNNLSTM)    (None, 5610, 32)          4480      \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_19 (CuDNNLSTM)    (None, 5610, 64)          25088     \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 359040)            0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 128)               45957248  \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 45,986,945\n",
            "Trainable params: 45,986,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None test 1.441348223076561 0.5916109707677322\n",
            "None train 0.36219389600969476 0.9759812656746322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-gPS5Xx2MDQ",
        "colab_type": "code",
        "outputId": "aad7c18e-ebd7-4a55-d9cd-1b2d39a1ba64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "def NN_model2(data= X_train):\n",
        "  inputs = Input(shape=data.shape[1:])\n",
        "  #inputs = Input(shape=(7,))\n",
        "  x = Dense(2048, activation=\"relu\")(inputs)\n",
        "#   x = Dropout(0.5)(x)\n",
        "#   x = Dense(2048, activation=\"relu\")(x)\n",
        "#   x = Dense(2048, activation=\"relu\")(x)\n",
        "#   x = Dense(512, activation=\"relu\")(x)\n",
        "#   x = Dense(256, activation=\"relu\")(x)\n",
        "#   x = Dense(64, activation=\"relu\")(x)\n",
        "#   x = Dense(16, activation=\"relu\")(x)\n",
        "  #x = Dropout(0.3)(x)\n",
        "  x = Dense(2048, activation=\"relu\")(x)\n",
        "  predictions = Dense(1)(x)\n",
        "  model = Model(inputs=inputs, outputs=predictions)\n",
        "  model.compile(optimizer=\"adam\",loss='mean_squared_error')\n",
        "  model.summary()\n",
        "  return model\n",
        "nn_model = NN_model2(X_train)\n",
        "nn2 = KerasRegressor(build_fn=NN_model2, epochs=100, batch_size=10, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4jeYD_rp-8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import normalize \n",
        "\n",
        "class sparseNorm(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        Y = normalize(sp.sparse.csc_matrix(X.values))\n",
        "        return Y\n",
        "lgbm = LGBMRegressor(boosting_type='gbdt', num_leaves= 60,learning_rate=0.06)\n",
        "rgf = RGFRegressor(max_leaf=1000, algorithm=\"RGF\",test_interval=100, loss=\"LS\",verbose=False,l2=1.0)\n",
        "rgf1 = RGFRegressor(max_leaf=1000, algorithm=\"RGF\",test_interval=100, loss=\"LS\",verbose=False,l2=1.0)\n",
        "rgf2 = RGFRegressor(max_leaf=1000, algorithm=\"RGF\",test_interval=100, loss=\"LS\",verbose=False,l2=1.0)\n",
        "rgf3 = RGFRegressor(max_leaf=1000, algorithm=\"RGF\",test_interval=100, loss=\"LS\",verbose=False,l2=1.0)\n",
        "rgf4 = RGFRegressor(max_leaf=1000, algorithm=\"RGF\",test_interval=100, loss=\"LS\",verbose=False,l2=1.0)\n",
        "\n",
        "pipe1 = make_pipeline(extMACCS(), rgf)\n",
        "pipe2 = make_pipeline(extMorgan(), rgf1)\n",
        "pipe3 = make_pipeline(extDescriptor(), rgf2)\n",
        "pipe4 = make_pipeline(extPCA(), rgf3)\n",
        "pipe7 =make_pipeline(extDescriptor(), rgf4)\n",
        "pipe8 =make_pipeline(extDescriptor(), rgf4)\n",
        "from fastFM import sgd,als\n",
        "\n",
        "fm = sgd.FMRegression(n_iter=1000, init_stdev=0.1, l2_reg_w=0,l2_reg_V=0, rank=2, step_size=0.1)\n",
        "fmpipe = make_pipeline(sparseNorm(),fm)\n",
        "\n",
        "ave = extAverage()\n",
        "xgb = xgboost.XGBRegressor()\n",
        "nbrs = KNeighborsRegressor(2)\n",
        "svr = SVR(gamma='auto',kernel='linear')\n",
        "sgd = SGDRegressor(max_iter=1000)\n",
        "pls = PLSRegression(n_components=3)\n",
        "ext = ExtraTreesRegressor(n_estimators=30,max_features= 20,min_samples_split= 5,max_depth= 50, min_samples_leaf= 5)\n",
        "\n",
        "pipe5 = make_pipeline(extMorgan(), nbrs)\n",
        "pipe6 = make_pipeline(extMACCS(), rgf)\n",
        "alldata = make_pipeline(extAll())\n",
        "\n",
        "meta = RandomForestRegressor(max_depth=20, random_state=0, n_estimators=400)\n",
        "\n",
        "pipe1 = make_pipeline(extMACCS(), meta)\n",
        "pipe2 = make_pipeline(extMorgan(), meta)\n",
        "pipe3 = make_pipeline(extDescriptor(), meta)\n",
        "pipe4 = make_pipeline(extPCA(), rgf3)\n",
        "\n",
        "pipe7 =make_pipeline(extDescriptor(), rgf4)\n",
        "pipe8 =make_pipeline(extDescriptor(), rgf4)\n",
        "\n",
        "stack = StackingRegressor(regressors=[pipe1,pipe2,pipe3,rgf,xgb,lgbm,meta], meta_regressor=ave, verbose=1)\n",
        "\n",
        "stack1 = StackingRegressor(regressors=[pipe1, pipe2, pipe3,nn,fmpipe,nn2], meta_regressor=rgf, verbose=1)\n",
        "#stack2 = StackingRegressor(regressors=[stack1,nbrs, svr,pls,rgf], meta_regressor=lgbm, verbose=1)\n",
        "stack2 = StackingRegressor(regressors=[stack1,pipe5,pipe7,pipe1], meta_regressor=rgf,verbose=1)\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa_tnvihBu8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0.70\n",
        "pipeRgf = make_pipeline(extMorgan(), rgf)\n",
        "pipeXgb = make_pipeline(extMorgan(), xgb)\n",
        "pipeLgbm = make_pipeline(extMorgan(), lgbm)\n",
        "pipeNbrs = make_pipeline(extMorgan(), nbrs)\n",
        "\n",
        "\n",
        "#stack = StackingRegressor(regressors=[pipe1,pipe2,pipe3,pipeRgf,pipeXgb,pipeLgbm], meta_regressor=ave, verbose=1)\n",
        "stack = StackingRegressor(regressors=[meta,rgf,xgb,lgbm], meta_regressor=ave, verbose=1)\n",
        "scores = cross_validate(stack, X, y, cv=cv)\n",
        "score = scores['test_score'].mean()**(1/2)\n",
        "score2 = scores['train_score'].mean()**(1/2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tan0oj5tJB3F",
        "colab_type": "code",
        "outputId": "65b353de-6b87-48b6-da2e-769e3ee3e9bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6992734576657249"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4muLHrjx2CjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#0.68\n",
        "pipePCA = make_pipeline(extPCA())\n",
        "\n",
        "stack1 = StackingRegressor(regressors=[pipe1, pipe2, pipe3], meta_regressor=meta, verbose=1)\n",
        "#0.68\n",
        "stack2 = StackingRegressor(regressors=[stack1,alldata,pipePCA,nbrs], meta_regressor=rgf,verbose=1)\n",
        "\n",
        "stack2 = StackingRegressor(regressors=[stack1,alldata,pipePCA,nbrs], meta_regressor=ave,verbose=1)\n",
        "scores2 = cross_validate(stack2, X, y, cv=cv)\n",
        "score3 = scores2['test_score'].mean()**(1/2)\n",
        "score4 = scores2['train_score'].mean()**(1/2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLeRvW0u8_rG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stack1 = StackingRegressor(regressors=[pipe1, pipe2, pipe3], meta_regressor=meta, verbose=1)\n",
        "stack2 = StackingRegressor(regressors=[stack1,alldata], meta_regressor=meta,verbose=1)\n",
        "scores3 = cross_validate(stack2, X, y, cv=cv)\n",
        "score5 = scores3['test_score'].mean()**(1/2)\n",
        "score6 = scores3['train_score'].mean()**(1/2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_peoRAEs8ugo",
        "colab_type": "code",
        "outputId": "cb227c32-e06a-43f8-82a6-66425a2e7e75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXH1sJg9cNrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipePCA = make_pipeline(extPCA())\n",
        "\n",
        "stack3 = StackingRegressor(regressors=[pipe1, pipe2, pipe3], meta_regressor=meta, verbose=1)\n",
        "stack4 = StackingRegressor(regressors=[stack1,alldata,pipePCA], meta_regressor=rgf,verbose=1)\n",
        "scores10 = cross_validate(stack4, X, y, cv=cv)\n",
        "score11 = scores10['test_score'].mean()**(1/2)\n",
        "score12 = scores10['train_score'].mean()**(1/2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd3aD3841Jie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ",rgf,xgb,lgbm,meta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7R8gPfIu9v1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stack = StackingRegressor(regressors=[pipe1,pipe2,pipe3], meta_regressor=ave, verbose=1)\n",
        "scores = cross_validate(stack, X, y, cv=cv)\n",
        "score = scores['test_score'].mean()**(1/2)\n",
        "score2 = scores['train_score'].mean()**(1/2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtPhiijEvcol",
        "colab_type": "code",
        "outputId": "5ac77dec-519c-4cc1-db61-99c673c6e547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6785203788102289"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SETgxXdtZjPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "singleResult = {}\n",
        "for name in [xgb,nbrs,svr,sgd,pls,ext,lgbm,rgf,meta,fmpipe]:\n",
        "  scores = cross_validate(name, X, y, cv=cv)\n",
        "  score = scores['test_score'].mean()**(1/2)\n",
        "  score2 = scores['train_score'].mean()**(1/2)\n",
        "  name2 = str(name)\n",
        "  singleResult[name] = (score,score2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwFuW-EAe8XW",
        "colab_type": "code",
        "outputId": "d2b364ef-7076-4876-8ab4-6ecc890e444f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([0.02854085, 0.01813841, 0.01846361, 0.01905918, 0.01943231,\n",
              "        0.01915932, 0.01916122, 0.0187676 , 0.0185051 , 0.01845622]),\n",
              " 'score_time': array([0.00297284, 0.00268865, 0.00284624, 0.00341225, 0.00285077,\n",
              "        0.00278807, 0.00270033, 0.00278497, 0.00265265, 0.00293851]),\n",
              " 'test_score': array([0.09979622, 0.1815943 , 0.17128182, 0.18970238, 0.31300673,\n",
              "        0.25077943, 0.25094152, 0.29138371, 0.28893897, 0.06266754]),\n",
              " 'train_score': array([0.18613029, 0.12032096, 0.21351814, 0.22544877, 0.30175647,\n",
              "        0.24757158, 0.35747028, 0.36475411, 0.35926899, 0.23259555])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UHq2TlLdR_x",
        "colab_type": "code",
        "outputId": "eb74ef83-877f-402a-a121-2e5bcef7c085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879
        }
      },
      "source": [
        "singleResult"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=50,\n",
              "           max_features=20, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
              "           min_impurity_split=None, min_samples_leaf=5, min_samples_split=5,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=None,\n",
              "           oob_score=False, random_state=None, verbose=0, warm_start=False): (0.6231301383871978,\n",
              "  0.7680167562613793),\n",
              " KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "           metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
              "           weights='uniform'): (0.5561273537929962, 0.8776402432176893),\n",
              " LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "        importance_type='split', learning_rate=0.06, max_depth=-1,\n",
              "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "        n_estimators=100, n_jobs=-1, num_leaves=60, objective=None,\n",
              "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0): (0.6740073058165706,\n",
              "  0.9385204557757585),\n",
              " PLSRegression(copy=True, max_iter=500, n_components=3, scale=True, tol=1e-06): (0.6087878772482173,\n",
              "  0.7387429922268596),\n",
              " Pipeline(memory=None,\n",
              "      steps=[('sparsenorm', sparseNorm()), ('fmregression', FMRegression(init_stdev=0.1, l2_reg=0, l2_reg_V=0, l2_reg_w=0, n_iter=1000,\n",
              "        random_state=123, rank=2, step_size=0.1))]): (0.45826767712319366,\n",
              "  0.5107675735399617),\n",
              " RGFRegressor(algorithm='RGF', init_model=None, l2=1.0, learning_rate=0.5,\n",
              "        loss='LS', max_leaf=1000, memory_policy='generous',\n",
              "        min_samples_leaf=10, n_iter=None, n_tree_search=1, normalize=True,\n",
              "        opt_interval=100, reg_depth=1.0, sl2=None, test_interval=100,\n",
              "        verbose=False): (0.6828725788699093, 0.849997190493384),\n",
              " RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=20,\n",
              "            max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=None,\n",
              "            oob_score=False, random_state=0, verbose=0, warm_start=False): (0.6938102422399695,\n",
              "  0.9585462892965368),\n",
              " SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
              "        eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
              "        learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
              "        n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
              "        random_state=None, shuffle=True, tol=None, validation_fraction=0.1,\n",
              "        verbose=0, warm_start=False): (0.3291565516025202, 0.8887763235337592),\n",
              " SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
              "   kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False): (nan,\n",
              "  0.860208752671646),\n",
              " XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "        colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
              "        max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
              "        n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
              "        reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "        silent=True, subsample=1): (0.6795526862156849, 0.8340105881644)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNnYTUb9zDGz",
        "colab_type": "code",
        "outputId": "d36b13fe-5481-4e8a-83ea-5d3f816f9aee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "lstm.fit(X_train, y_train)\n",
        "y_pred = lstm.predict(X_train)\n",
        "y_val = lstm.predict(X_test)\n",
        "print(\"Root Mean Squared Error train: %.4f\" % calcRMSE(y_pred, y_train))\n",
        "print(\"Root Mean Squared Error test: %.4f\" % calcRMSE(y_val, y_test))\n",
        "print('Correlation Coefficient train: %.4f' % calcCorr(y_pred, y_train))\n",
        "print('Correlation Coefficient test: %.4f' % calcCorr(y_val, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_4 (CuDNNLSTM)     (None, 690, 224)          203392    \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_5 (CuDNNLSTM)     (None, 690, 384)          936960    \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 264960)            0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 264960)            0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               33915008  \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 35,055,489\n",
            "Trainable params: 35,055,489\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Root Mean Squared Error train: 0.2412\n",
            "Root Mean Squared Error test: 1.5216\n",
            "Correlation Coefficient train: 0.9898\n",
            "Correlation Coefficient test: 0.4670\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSLJhyIfR-lj",
        "colab_type": "code",
        "outputId": "74139e80-3e76-4731-9a48-429d20a72deb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "print(y_val,y_val.shape)\n",
        "y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125\n",
            " 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125 0.14148125] (126,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(126,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsT3T11nSKiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijUmrQYM1rAC",
        "colab_type": "code",
        "outputId": "f4c47a37-8b14-4f4a-f53c-b1be6099b8a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3378
        }
      },
      "source": [
        "scores = cross_validate(nn, X, y, cv=cv)\n",
        "scores['test_score'].mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_71 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_93 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_68 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_68 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_139 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_140 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_72 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_94 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_69 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_69 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_141 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_142 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_73 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_95 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_70 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_70 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_143 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_144 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_74 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_96 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_71 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_71 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_145 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_146 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_75 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_97 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_72 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_72 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_147 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_148 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_76 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_98 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_73 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_73 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_149 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_150 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_77 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_99 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_74 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_74 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_151 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_152 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_78 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_100 (Conv1D)          (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_75 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_75 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_153 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_154 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_79 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_101 (Conv1D)          (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_76 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_76 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_155 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_156 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_80 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_102 (Conv1D)          (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_77 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_77 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_157 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_158 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.55726209964071"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdI7qt1qyMEy",
        "colab_type": "code",
        "outputId": "bd6cf804-e962-4111-82d8-977a7373eff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([17.53997922, 17.51591349, 17.62641382, 18.63325047, 18.35314131,\n",
              "        18.77135444, 19.03872037, 19.38783813, 20.17999578, 19.95681596]),\n",
              " 'score_time': array([2.63622236, 2.81975174, 2.88187885, 2.97793388, 3.18758726,\n",
              "        3.28418374, 3.39250493, 3.42442966, 3.53948808, 3.70629454]),\n",
              " 'test_score': array([-1.87397503, -1.48971084, -1.21239327, -1.56403474, -2.68844223,\n",
              "        -2.90050378, -2.04052038, -1.72630579, -1.75029235, -1.57858052]),\n",
              " 'train_score': array([-0.05194089, -1.44330622, -0.09889857, -1.31023485, -2.67425018,\n",
              "        -2.65073041, -1.82119017, -1.13014557, -0.08168194, -1.48566212])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3fKyQKbpbtA",
        "colab_type": "code",
        "outputId": "633345bf-7d8d-418a-c123-2a5615888625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8148
        }
      },
      "source": [
        "scores = cross_validate(stack2, X, y, cv=10)\n",
        "scores['test_score'].mean()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 4 regressors...\n",
            "Fitting regressor1: stackingregressor (1/4)\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_24 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_21 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_21 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_25 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor2: pipeline (2/4)\n",
            "Fitting regressor3: pipeline (3/4)\n",
            "Fitting regressor4: pipeline (4/4)\n",
            "Fitting 4 regressors...\n",
            "Fitting regressor1: stackingregressor (1/4)\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_26 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_22 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_22 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_27 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor2: pipeline (2/4)\n",
            "Fitting regressor3: pipeline (3/4)\n",
            "Fitting regressor4: pipeline (4/4)\n",
            "Fitting 4 regressors...\n",
            "Fitting regressor1: stackingregressor (1/4)\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_28 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_23 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_23 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_29 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_61 (Dense)             (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor2: pipeline (2/4)\n",
            "Fitting regressor3: pipeline (3/4)\n",
            "Fitting regressor4: pipeline (4/4)\n",
            "Fitting 4 regressors...\n",
            "Fitting regressor1: stackingregressor (1/4)\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_30 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_24 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_24 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_31 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor2: pipeline (2/4)\n",
            "Fitting regressor3: pipeline (3/4)\n",
            "Fitting regressor4: pipeline (4/4)\n",
            "Fitting 4 regressors...\n",
            "Fitting regressor1: stackingregressor (1/4)\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_32 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_25 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_25 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_33 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor2: pipeline (2/4)\n",
            "Fitting regressor3: pipeline (3/4)\n",
            "Fitting regressor4: pipeline (4/4)\n",
            "Fitting 4 regressors...\n",
            "Fitting regressor1: stackingregressor (1/4)\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_34 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_26 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_26 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_35 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor2: pipeline (2/4)\n",
            "Fitting regressor3: pipeline (3/4)\n",
            "Fitting regressor4: pipeline (4/4)\n",
            "Fitting 4 regressors...\n",
            "Fitting regressor1: stackingregressor (1/4)\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_36 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_27 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_27 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_37 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_80 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_81 (Dense)             (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_82 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor2: pipeline (2/4)\n",
            "Fitting regressor3: pipeline (3/4)\n",
            "Fitting regressor4: pipeline (4/4)\n",
            "Fitting 4 regressors...\n",
            "Fitting regressor1: stackingregressor (1/4)\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_38 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_28 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_28 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_83 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_84 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_39 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_85 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_86 (Dense)             (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_87 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor2: pipeline (2/4)\n",
            "Fitting regressor3: pipeline (3/4)\n",
            "Fitting regressor4: pipeline (4/4)\n",
            "Fitting 4 regressors...\n",
            "Fitting regressor1: stackingregressor (1/4)\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_40 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_29 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_29 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_88 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_89 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_41 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_90 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_91 (Dense)             (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_92 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor2: pipeline (2/4)\n",
            "Fitting regressor3: pipeline (3/4)\n",
            "Fitting regressor4: pipeline (4/4)\n",
            "Fitting 4 regressors...\n",
            "Fitting regressor1: stackingregressor (1/4)\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_42 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_30 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_30 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_93 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_94 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_43 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_95 (Dense)             (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_96 (Dense)             (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_97 (Dense)             (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor2: pipeline (2/4)\n",
            "Fitting regressor3: pipeline (3/4)\n",
            "Fitting regressor4: pipeline (4/4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.19763957, 0.28065453, 0.37411911, 0.39152718, 0.4430288 ,\n",
              "       0.48997388, 0.60091479, 0.48158644, 0.43197961, 0.22167769])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyQie9B4w8Ov",
        "colab_type": "code",
        "outputId": "f5c6e8f6-ec85-4ef2-c752-27e5a4b0edc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scores.mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39131016006993274"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QvGXiwqu9ge",
        "colab_type": "code",
        "outputId": "712981c1-2542-4a4c-f933-7c4b15da16f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7446
        }
      },
      "source": [
        "stack_scores =cross_validate(stack1, X, y, cv=10)\n",
        "stack_scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_50 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_34 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_34 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_113 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_114 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_51 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_115 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_116 (Dense)            (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_117 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_52 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_35 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_35 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_118 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_119 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_53 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_120 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_121 (Dense)            (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_122 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_54 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_36 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_36 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_123 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_124 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_55 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_125 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_126 (Dense)            (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_127 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_56 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_37 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_37 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_128 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_129 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_57 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_130 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_131 (Dense)            (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_132 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_58 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_38 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_38 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_133 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_134 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_59 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_135 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_136 (Dense)            (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_137 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_60 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_39 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_39 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_138 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_139 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_61 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_140 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_141 (Dense)            (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_142 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_62 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_40 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_40 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_143 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_144 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_63 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_145 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_146 (Dense)            (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_147 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_64 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_41 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_41 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_148 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_149 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_65 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_150 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_151 (Dense)            (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_152 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_66 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_42 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_42 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_153 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_154 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_67 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_155 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_156 (Dense)            (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_157 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting 6 regressors...\n",
            "Fitting regressor1: pipeline (1/6)\n",
            "Fitting regressor2: pipeline (2/6)\n",
            "Fitting regressor3: pipeline (3/6)\n",
            "Fitting regressor4: pipeline (4/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_68 (InputLayer)        (None, 690, 1)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_43 (Conv1D)           (None, 690, 1)            2         \n",
            "_________________________________________________________________\n",
            "flatten_43 (Flatten)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_158 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_159 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 1,417,219\n",
            "Trainable params: 1,417,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Fitting regressor5: pipeline (5/6)\n",
            "Fitting regressor6: kerasregressor (6/6)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_69 (InputLayer)        (None, 690)               0         \n",
            "_________________________________________________________________\n",
            "dense_160 (Dense)            (None, 2048)              1415168   \n",
            "_________________________________________________________________\n",
            "dense_161 (Dense)            (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dense_162 (Dense)            (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 5,613,569\n",
            "Trainable params: 5,613,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([133.56943321, 135.46863294, 135.77038169, 136.78971791,\n",
              "        138.16432285, 139.50198388, 140.6641326 , 141.19012785,\n",
              "        143.97067618, 144.0953393 ]),\n",
              " 'score_time': array([0.35180521, 0.35023689, 0.35720897, 0.36406612, 0.35870647,\n",
              "        0.37927723, 0.38316083, 0.36888576, 0.38707685, 0.36656427]),\n",
              " 'test_score': array([0.30323613, 0.26691208, 0.33824475, 0.4089086 , 0.38580084,\n",
              "        0.47605946, 0.60830864, 0.5006599 , 0.40077139, 0.16564585]),\n",
              " 'train_score': array([0.983355  , 0.99007855, 0.98353844, 0.9835329 , 0.9840576 ,\n",
              "        0.98359359, 0.9835808 , 0.9813044 , 0.98336132, 0.98668905])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIRmnW9WyEjE",
        "colab_type": "code",
        "outputId": "d0d38fcf-be46-4761-a207-2c755c59cd28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stack_scores['test_score'].mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3854547633234017"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB3J9bAH0Zm5",
        "colab_type": "code",
        "outputId": "f579f8bd-0480-4077-a5f5-eae175cc6a16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "rgf_scores=cross_validate(rgf, X, y, cv=10)\n",
        "print(rgf_scores)\n",
        "rgf_scores.mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.34539658 0.37707443 0.40949323 0.40390886 0.42384531 0.45379597\n",
            " 0.6097257  0.42279969 0.46854228 0.49224834]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4406830390639035"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}